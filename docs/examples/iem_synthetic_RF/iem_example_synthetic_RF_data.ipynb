{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverted encoding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from brainiak.reconstruct import iem as IEM\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.matlib as matlib\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will assume that the stimuli are patches of different motion directions. These stimuli span a 360-degree, circular feature space. We will build an encoding model that has 6 channels, or basis functions, which also span this feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "n_channels = 6\n",
    "cos_exponent = 5\n",
    "range_start = 0\n",
    "\n",
    "range_stop = 360\n",
    "feature_resolution = 360\n",
    "iem_obj = IEM.InvertedEncoding1D(n_channels, cos_exponent, stimulus_mode='circular', range_start=range_start, \n",
    "                               range_stop=range_stop, channel_density=feature_resolution)\n",
    "\n",
    "# You can also try the half-circular space. Here's the associated code:\n",
    "# range_stop = 180  # since 0 and 360 degrees are the same, we want to stop shy of 360\n",
    "# feature_resolution = 180\n",
    "# iem_obj = IEM.InvertedEncoding1D(n_channels, cos_exponent, stimulus_mode='halfcircular', range_start=range_start, \n",
    "#                                range_stop=range_stop, channel_density=feature_resolution, verbose=True)\n",
    "\n",
    "stim_vals = np.linspace(0, feature_resolution - (feature_resolution/6), 6).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll generate synthetic data. Ideally, each voxel that we measure from is roughly tuned to some part of the feature space (see Sprague, Boynton, Serences, 2019). So we will generate data that has a receptive field (RF). We can define the RF along the same feature axis as the channels that we generated above.\n",
    "\n",
    "The following two functions will generate the voxel RFs, and then generate several trials of that dataset. There are options to add uniform noise to either the RF or the trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data s.t. each voxel has a Gaussian tuning function\n",
    "\n",
    "def generate_voxel_RFs(n_voxels, feature_resolution, random_tuning=True, RF_noise=0.):\n",
    "    if random_tuning:\n",
    "        # Voxel selectivity is random\n",
    "        voxel_tuning = np.floor((np.random.rand(n_voxels) * range_stop) + range_start).astype(int)\n",
    "    else:\n",
    "        # Voxel selectivity is evenly spaced along the feature axis\n",
    "        voxel_tuning = np.linspace(range_start, range_stop, n_voxels+1)\n",
    "        voxel_tuning = voxel_tuning[0:-1]\n",
    "        voxel_tuning = np.floor(voxel_tuning).astype(int)\n",
    "    gaussian = scipy.signal.gaussian(feature_resolution, 15)\n",
    "    voxel_RFs = np.zeros((n_voxels, feature_resolution))\n",
    "    for i in range(0, n_voxels):\n",
    "        voxel_RFs[i, :] = np.roll(gaussian, voxel_tuning[i] - ((feature_resolution//2)-1))\n",
    "    voxel_RFs += np.random.rand(n_voxels, feature_resolution)*RF_noise  # add noise to voxel RFs\n",
    "    voxel_RFs = voxel_RFs / np.max(voxel_RFs, axis=1)[:, None]\n",
    "    \n",
    "    return voxel_RFs, voxel_tuning\n",
    "\n",
    "\n",
    "def generate_voxel_data(voxel_RFs, n_voxels, trial_list, feature_resolution, \n",
    "                         trial_noise=0.25):\n",
    "    one_hot = np.eye(feature_resolution)\n",
    "    # Generate trial-wise responses based on voxel RFs\n",
    "    if range_start > 0:\n",
    "        trial_list = trial_list + range_start\n",
    "    elif range_start < 0:\n",
    "        trial_list = trial_list - range_start\n",
    "    stim_X = one_hot[:, trial_list] #@ basis_set.transpose()\n",
    "    trial_data = voxel_RFs @ stim_X\n",
    "    trial_data += np.random.rand(n_voxels, trial_list.size)*(trial_noise*np.max(trial_data))\n",
    "    \n",
    "    return trial_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate some training data and look at it. This code will create a plot that depicts the response of an example voxel for different trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "n_voxels = 50\n",
    "n_train_trials = 120\n",
    "training_stim = np.repeat(stim_vals, n_train_trials/6)\n",
    "voxel_RFs, voxel_tuning = generate_voxel_RFs(n_voxels, feature_resolution, random_tuning=False, RF_noise=0.1)\n",
    "train_data = generate_voxel_data(voxel_RFs, n_voxels, training_stim, feature_resolution, trial_noise=0.25)\n",
    "print(np.linalg.cond(train_data))\n",
    "# print(\"Voxels are tuned to: \", voxel_tuning)\n",
    "\n",
    "# Generate plots to look at the RF of an example voxel.\n",
    "voxi = 20\n",
    "f = plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_data[voxi, :])\n",
    "plt.xlabel(\"trial\")\n",
    "plt.ylabel(\"activation\")\n",
    "plt.title(\"Activation over trials\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(voxel_RFs[voxi, :])\n",
    "plt.xlabel(\"degrees (motion direction)\")\n",
    "plt.axvline(voxel_tuning[voxi])\n",
    "plt.title(\"Receptive field at {} deg\".format(voxel_tuning[voxi]))\n",
    "plt.suptitle(\"Example voxel\")\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(train_data)\n",
    "plt.ylabel('voxel')\n",
    "plt.xlabel('trial')\n",
    "plt.suptitle('Simulated data from each voxel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this synthetic training data, we can fit the IEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an IEM\n",
    "iem_obj.fit(train_data.transpose(), training_stim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the IEM fit method defines the channels, or the basis set, which span the feature domain. We can examine the channels and plot them to check that they look appropriate.\n",
    "\n",
    "Remember that the plot below is in circular space. Hence, the channels wrap around the x-axis. For example, the channel depicted in blue is centered at 0 degrees (far left of plot), which is the same as 360 degrees (far right of plot).\n",
    "\n",
    "We can check whether the channels properly tile the feature space by summing across all of them. This is shown on the right plot. It should be a straight horizontal line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the basis functions.\n",
    "channels = iem_obj.channels_\n",
    "feature_axis = iem_obj.channel_domain\n",
    "print(channels.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "for i in range(0, channels.shape[0]):\n",
    "    plt.plot(feature_axis, channels[i,:])\n",
    "plt.title('Channels (i.e. basis functions)')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(np.sum(channels, 0))\n",
    "plt.ylim(0, 2.5)\n",
    "plt.title('Sum across channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can generate test data and see how well we can predict the test stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "n_test_trials = 12\n",
    "test_stim = np.repeat(stim_vals, n_test_trials/len(stim_vals))\n",
    "np.random.seed(330)\n",
    "test_data = generate_voxel_data(voxel_RFs, n_voxels, test_stim, feature_resolution, trial_noise=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test stim & get R^2 score\n",
    "pred_feature = iem_obj.predict(test_data.transpose())\n",
    "R2 = iem_obj.score(test_data.transpose(), test_stim)\n",
    "\n",
    "print(\"Predicted features are: {} degrees.\".format(pred_feature))\n",
    "print(\"Actual features are: {} degrees.\".format(test_stim))\n",
    "print(\"Test R^2 is {}\".format(R2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to predicting the exact feature, we can examine the model-based reconstructions in the feature domain. That is, instead of getting single predicted values for each feature, we can look at a reconstructed function which peaks at the predicted feature.\n",
    "\n",
    "Below we will plot all of the reconstructions. There will be some variability because of the noise added during the synthetic data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get the model-based reconstructions, which are continuous\n",
    "# functions that should peak at each test stimulus feature\n",
    "recons = iem_obj._predict_feature_responses(test_data.transpose())\n",
    "\n",
    "f = plt.figure()\n",
    "for i in range(0, n_test_trials-1):\n",
    "    plt.plot(feature_axis, recons[:, i])\n",
    "for i in stim_vals:\n",
    "    plt.axvline(x=i, color='k', linestyle='--')\n",
    "\n",
    "plt.title(\"Reconstructions of {} degrees\".format(np.unique(test_stim)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a sanity check, let's check how R^2 changes as the number of voxels increases. We can write a quick wrapper function to train and test on a given set of motion directions, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iem_obj.verbose = False\n",
    "def train_and_test(nvox, ntrn, ntst, rfn, tn):\n",
    "    vRFs, vox_tuning = generate_voxel_RFs(nvox, feature_resolution, random_tuning=True, RF_noise=rfn)\n",
    "    trn = np.repeat(stim_vals, ntrn/6).astype(int)\n",
    "    trnd = generate_voxel_data(vRFs, nvox, trn, feature_resolution, trial_noise=tn)\n",
    "    tst = np.repeat(stim_vals, ntst/6).astype(int)\n",
    "    tstd = generate_voxel_data(vRFs, nvox, tst, feature_resolution, trial_noise=tn)\n",
    "    \n",
    "    iem_obj.fit(trnd.transpose(), trn)\n",
    "    recons = iem_obj._predict_feature_responses(tstd.transpose())\n",
    "    pred_ori = iem_obj.predict(tstd.transpose())\n",
    "    R2 = iem_obj.score(tstd.transpose(), tst)\n",
    "\n",
    "    return recons, pred_ori, R2, tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll iterate through the list and look at the resulting R^2 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(300)\n",
    "vox_list = (5, 10, 15, 25, 50)\n",
    "R2_list = np.zeros(len(vox_list))\n",
    "for idx, nvox in enumerate(vox_list):\n",
    "    recs, preds, R2_list[idx], test_features = train_and_test(nvox, 120, 30, 0.1, 0.25)\n",
    "\n",
    "print(\"The R2 values for increasing numbers of voxels: \")\n",
    "print(R2_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
