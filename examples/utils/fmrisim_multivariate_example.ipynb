{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2016 Intel Corporation\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRI Simulator example script for multivariate analyses\n",
    "\n",
    "Example script to demonstrate fmrisim functionality. This generates\n",
    "data for a two condition, event related design in which each condition\n",
    "evokes different activity within the same voxels. It then runs simple \n",
    "univariate and multivariate analyses on the data\n",
    "\n",
    "Authors: Cameron Ellis (Yale) 2017\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.\tSet parameters.** \n",
    "\n",
    "It is necessary to set various parameters that describe how the signal and the noise will be generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1.1 Import necessary Python packages*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from pathlib import Path\n",
    "from brainiak.utils import fmrisim\n",
    "import nibabel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.spatial.distance as sp_distance\n",
    "import sklearn.manifold as manifold\n",
    "import scipy.stats as stats\n",
    "import sklearn.model_selection\n",
    "import sklearn.svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1.2 Load participant data*\n",
    "\n",
    "Any 4 dimensional fMRI data that is readible by nibabel can be used as input to this pipeline. For this example, data is taken from the open access repository DataSpace: http://arks.princeton.edu/ark:/88435/dsp01dn39x4181. This file is unzipped and placed in the home directory with the name Corr_MVPA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home = str(Path.home())\n",
    "nii = nibabel.load(home + '/Corr_MVPA/Participant_01_rest_run01.nii')\n",
    "volume = nii.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1.2\tSpecify participant dimensions and resolution*\n",
    "\n",
    "The size of the volume and the resolution of the voxels must be specified (or extracted from the real data as is the case below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = volume.shape  # What is the size of the volume\n",
    "dimsize = nii.header.get_zooms()  # Get voxel dimensions from the nifti header\n",
    "tr = dimsize[3]\n",
    "if tr > 100:  # If high then these values are likely in ms\n",
    "    tr /= 1000\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1.3 Generate an activity template and a mask*\n",
    "\n",
    "Functions in fmrisim require a continuous map that describes the appropriate average MR value for each voxel in the brain and a mask which specifies voxels in the brain versus voxels outside of the brain. One way to generate both of these volumes is the mask_brain function. At a minimum, this takes as an input the fMRI volume to be simulated. To create the template this volume is averaged over time and bounded to a range from 0 to 1. In other words, voxels with a high value in the template have high activity over time. To create a mask, the template is thresholded.  This threshold can be set manually or instead an appropriate value can be determined by looking for the minima between the two first peaks in the histogram of voxel values. If you would prefer, you could use the [compute_epi_mask](http://nilearn.github.io/modules/generated/nilearn.masking.compute_epi_mask.html) function in nilearn which uses a similar method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask, template = fmrisim.mask_brain(volume=volume, \n",
    "                                    mask_self=True,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1.4 Determine noise parameters*\n",
    "\n",
    "A critical step in the fmrisim toolbox is determining the noise parameters of the volume to be created. Many noise parameters are available for specification and if any are not set then they will default to reasonable values. As mentioned before, it is instead possible to provide raw fMRI data that will be used to estimate these noise parameters. The goal of the noise estimation is to calculate general descriptive statistics about the noise in the brain that are thought to be important. The simulations are then useful for understanding how signals will survive analyses when embedded in realistic neural noise. \n",
    "\n",
    "Now the disclaimers: the values here are only an estimate and will depend on noise properties combining in the ways assumed. In addition, because of the non-linearity and stochasticity of this simulation, this estimation is not fully invertible: if you generate a dataset with a set of noise parameters it will have similar but not the same noise parameters as a result. Moreover, complex interactions between brain regions that likely better describe brain noise are not modelled here: this toolbox pays no attention to regions of the brain or their interactions. Finally, for best results use raw fMRI because if the data has been preprocessed then assumptions this algorithm makes are likely to be erroneous. For instance, if the brain has been masked then this will eliminate variance in non-brain voxels which will mean that calculations of noise dependent on those voxels as a reference will fail.\n",
    "\n",
    "This toolbox separates noise in two: spatial noise and temporal noise. To estimate spatial noise both the smoothness and the amount of non-brain noise of the data must be quantified. For smoothness, the Full Width Half Max (FWHM) of the volume is averaged for the X, Y and Z dimension and then averaged across a sample of time points. To calculate the Signal to Noise Ratio (SNR) the mean activity in brain voxels for the middle time point is divided by the standard deviation in activity across non-brain voxels for that time point. For temporal noise an Auto-regressive and moving average (ARMA) process is estimated, along with the overall size of temporal variability. A sample of brain voxels is used to estimate the first two AR components and the first MA component of each voxel's activity over time using the statsmodels package. The Signal to Fluctuation Noise Ratio (SFNR) is calculated by dividing the average activity of voxels in the brain with that voxel’s noise  (Friedman & Glover, 2006). That noise is calculated by taking the standard deviation of that voxel over time after it has been detrended with a second order polynomial. The SFNR then controls the amount of functional variability. Other types of noise can be generated, such as physiological noise, but are not estimated by this function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the noise parameters from the data\n",
    "noise_dict = {'voxel_size': [dimsize[0], dimsize[1], dimsize[2]]}\n",
    "noise_dict = fmrisim.calc_noise(volume=volume,\n",
    "                                mask=mask,\n",
    "                                template=template,\n",
    "                                noise_dict=noise_dict,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Noise parameters of the data were estimated as follows:')\n",
    "print('SNR: ' + str(noise_dict['snr']))\n",
    "print('SFNR: ' + str(noise_dict['sfnr']))\n",
    "print('FWHM: ' + str(noise_dict['fwhm']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Generate signal**\n",
    "fmrisim can generate realistic fMRI noise when supplied with the appropriate inputs. A single function receives these inputs and deals with generating the noise. The necessary inputs are described below; however, the steps performed by this function are also described in detail for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the noise given the parameters\n",
    "noise = fmrisim.generate_noise(dimensions=dim[0:3],\n",
    "                               tr_duration=int(tr),\n",
    "                               stimfunction_tr=[0] * dim[3], \n",
    "                               mask=mask,\n",
    "                               template=template,\n",
    "                               noise_dict=noise_dict,\n",
    "                               iterations=[50,0],\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a slice through the noise brain\n",
    "plt.figure()\n",
    "plt.imshow(noise[:, :, int(dim[2] / 2), 0], cmap=plt.cm.gray)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2.1 Create temporal noise*\n",
    "\n",
    "The temporal noise of fMRI data is comprised of multiple components: drift, autoregression, task related motion and physiological noise. To estimate drift, a number of cosine basis functions are combined. To estimate drift, cosine basis functions are combined, with longer runs being comprised of more basis functions (Welvaert, et al., 2011). This drift is then multiplied by a three-dimensional volume of Gaussian random fields of a specific FWHM. Autoregression noise is estimated by initializing with a brain shaped volume of gaussian random fields and then multiplying then creating an ARMA time course by adding additional volumes of noise. Physiological noise is modeled by sine waves comprised of heart rate (1.17Hz) and respiration rate (0.2Hz) (Biswal, et al., 1996) with random phase. This time course is also multiplied by brain shaped spatial noise. Finally, task related noise is simulated by adding Gaussian or Rician noise to time points where there are events (according to the event time course) and in turn this is multiplied by a brain shaped spatial noise volume. These four noise components are then mixed together in proportion to the size of their corresponding sigma values. This aggregated volume is then Z scored and the SFNR is used to estimate the appropriate standard deviation of these values across time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spatial noise\n",
    "low_spatial = fmrisim._generate_noise_spatial(dim[0:3],\n",
    "                                              fwhm=4.0,\n",
    "                                              )\n",
    "\n",
    "high_spatial = fmrisim._generate_noise_spatial(dim[0:3],\n",
    "                                               fwhm=1.0,\n",
    "                                               )\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('FWHM = 4.0')\n",
    "plt.imshow(low_spatial[:, :, 12])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('FWHM = 1.0')\n",
    "plt.imshow(high_spatial[:, :, 12])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the different types of noise\n",
    "total_time = 500\n",
    "timepoints = list(range(0, total_time, int(tr)))\n",
    "\n",
    "drift = fmrisim._generate_noise_temporal_drift(total_time,\n",
    "                                               int(tr),\n",
    "                                               )\n",
    "\n",
    "mini_dim = np.array([2, 2, 2])\n",
    "autoreg = fmrisim._generate_noise_temporal_autoregression(timepoints,\n",
    "                                                          noise_dict,\n",
    "                                                          mini_dim,\n",
    "                                                          np.ones(mini_dim),\n",
    "                                                          np.ones(mini_dim),\n",
    "                                                          )\n",
    "            \n",
    "phys = fmrisim._generate_noise_temporal_phys(timepoints,\n",
    "                                            )\n",
    "\n",
    "stimfunc = np.zeros((int(total_time / tr), 1))\n",
    "stimfunc[np.random.randint(0, int(total_time / tr), 50)] = 1\n",
    "task = fmrisim._generate_noise_temporal_task(stimfunc,\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the different noise types\n",
    "plt.figure()\n",
    "plt.title('Noise types')\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(drift)\n",
    "plt.axis('off')\n",
    "plt.xlabel('Drift')\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(autoreg[0, 0, 0, :])\n",
    "plt.axis('off')\n",
    "plt.xlabel('Autoregression')\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(phys)\n",
    "plt.axis('off')\n",
    "plt.xlabel('Physiological')\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(task)\n",
    "plt.axis('off')\n",
    "plt.xlabel('Task')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2.2 Create system noise*\n",
    "    \n",
    "In addition to temporal noise from fluctuations in the scanner there is also machine noise that causes fluctuations in all voxels. When SNR is low, Rician noise is a good estimate of background noise data (Gudbjartsson, & Patz, 1995). However if you look at the distribution of voxel values averaged across time then you see that this is also rician, suggesting that most of the rician noise is a result of the structure in the background of the brain (e.g. the baseline MR of the head coil or skull). If you subtract this baseline then the noise becomes approximately gaussian, especially in the regions far from the brain (which is what the calc_noise algorithm considers when calculating SNR). Hence the machine noise here is gaussian added to an inherently rician baseline.\n",
    "\n",
    "Below we take the distribution of voxel intensity for voxels that are more than 5 units away from the brain voxels. We then plot those voxels as a histogram at the first timepoint. Next we take a sample of voxels and display the distribution of intensity for these voxels over time, the lines indicating that the values are relatively stable. The last plot shows the distribution of values for the non-brain voxels after their baseline is removed which is a kurtotic gaussian (the peak reflects zero values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dilate the mask so as to only take voxels far from the brain (performed in calc_noise)\n",
    "mask_dilated = ndimage.morphology.binary_dilation(mask, iterations=10)\n",
    "\n",
    "# Remove all non brain voxels\n",
    "system_all = volume[mask_dilated == 0]  # Pull out all the non brain voxels in the first TR\n",
    "system_baseline = volume - (template.reshape(dim[0], dim[1], dim[2], 1) * noise_dict['max_activity'])  # Subtract the baseline before masking\n",
    "system_baseline = system_baseline[mask_dilated == 0]\n",
    "\n",
    "# Plot the distribution of voxels\n",
    "plt.figure()\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(system_all[:,0].flatten(),100)\n",
    "plt.xlabel('Activity')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Identify a subset of voxels to plot\n",
    "idxs = list(range(system_all.shape[0]))\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "temporal = system_all[idxs[:100], :100]\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(temporal)\n",
    "plt.axis('off')\n",
    "plt.title('Temporal')\n",
    "\n",
    "# Plot the difference\n",
    "ax=plt.subplot(1, 3, 3)\n",
    "plt.hist(system_baseline[:,0].flatten(),100)\n",
    "ax.yaxis.tick_right()\n",
    "ax.yaxis.set_label_position(\"right\")\n",
    "plt.xlabel('Activity difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2.3 Combine noise and template*\n",
    "    \n",
    "The template volume is used to estimate the appropriate baseline distribution of MR values. This estimate is then combined with the temporal noise and the system noise to make an estimate of the noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2.4 Fit the data to the noise parameters*\n",
    "\n",
    "The generate_noise function does its best to estimate the appropriate noise parameters using assumptions about noise sources; however, because of the complexity of these different noise types, it is often wrong. To compensate, fitting is performed in which parameters involved in the noise generation process are changed and the noise metrics are recalculated to see whether those changes helped the fit. Due to their importance, the parameters that can be fit are SNR, SFNR and AR.\n",
    "\n",
    "The fitting of SNR/SFNR involves reweighting spatial and temporal metrics of noise. This analysis is relatively quick because this reweighting does not require that any timecourses are recreated, only that they are reweighted. At least 10 iterations are recommended because the initial guesses tend to underestimate SFNR and SNR (although the size of this error depends on the data). In the case of fitting the AR, the MA rho is adjusted until the AR is appropriate and in doing so the timecourse needs to be recreated for each iteration. The default number of AR iterations is 0 because by default these values are in an appropriate range. However, at least 10 iterations are needed if you wish to match your output data to the exact input data.\n",
    "\n",
    "In terms of timing, for a medium size dataset (64x64x27x294 voxels) it takes approximately 23s to generate the data with 0 iterations on a Mac 2014 laptop. For every iteration of fitting the SNR/SFNR, it takes an additional 3s and for every additional iteration of fitting AR it takes an additional 10s (these combine linearly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the noise parameters for the simulated noise\n",
    "noise_dict_sim = {'voxel_size': [dimsize[0], dimsize[1], dimsize[2]]}\n",
    "noise_dict_sim = fmrisim.calc_noise(volume=noise,\n",
    "                                    mask=mask,\n",
    "                                    template=template,\n",
    "                                    noise_dict=noise_dict_sim,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SNR: %0.2f vs %0.2f' % (noise_dict['snr'], noise_dict_sim['snr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Compare noise parameters for the real and simulated noise:')\n",
    "print('SNR: %0.2f vs %0.2f' % (noise_dict['snr'], noise_dict_sim['snr']))\n",
    "print('SFNR: %0.2f vs %0.2f' % (noise_dict['sfnr'], noise_dict_sim['sfnr']))\n",
    "print('FWHM: %0.2f vs %0.2f' % (noise_dict['fwhm'], noise_dict_sim['fwhm']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Generate signal**\n",
    "\n",
    "fmrisim can be used to generate signal in a number of different ways depending on the type of effect being simulated. Several tools are supplied to help with different types of signal that may be required; however, custom scripts may be necessary for unique effects. Below an experiment will be simulated in which two conditions, A and B, evoke different patterns of activity in the same set of voxels in the brain. This pattern does not manifest as a univariate change in voxel activity across voxels but instead each condition evokes a consistent pattern across voxels. These conditions are randomly intermixed trial by trial. This code could be easily changed to instead compare univariate changes  evoked by stimuli in different brain regions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3.1 Specify which voxels in the brain contain signal*\n",
    "\n",
    "fmrisim provides tools to specify certain voxels in the brain that contain signal. The generate_signal function can produce regions of activity in a brain of different shapes, such as cubes, loops and spheres. Alternatively a volume could be loaded in that specifies the signal voxels (e.g. for ROIs from nilearn). The value of each voxel can be specified here, or set to be a random value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the region of activity where signal will appear\n",
    "coordinates = np.array([[21, 21, 21]])  # Where in the brain is the signal\n",
    "feature_size = 3  # How big, in voxels, is the size of the ROI\n",
    "signal_volume = fmrisim.generate_signal(dimensions=dim[0:3],\n",
    "                                        feature_type=['cube'],\n",
    "                                        feature_coordinates=coordinates,\n",
    "                                        feature_size=[feature_size],\n",
    "                                        signal_magnitude=[1],\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(signal_volume[:, :, 21], cmap=plt.cm.gray)\n",
    "plt.imshow(mask[:, :, 21], cmap=plt.cm.gray, alpha=.5)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3.2 Characterize signal for voxels*\n",
    "\n",
    "Specify the pattern of activity across a given number of voxels that characterizes each condition. This pattern can simply be random, as is done here, or can be structured, like the position of voxels in high dimensional representation space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a pattern for each voxel in our signal ROI\n",
    "voxels = feature_size ** 3\n",
    "\n",
    "# Pull the conical voxel activity from a uniform distribution\n",
    "pattern_A = np.random.rand(voxels).reshape((voxels, 1))  \n",
    "pattern_B = np.random.rand(voxels).reshape((voxels, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pattern of activity for each condition\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(pattern_A)\n",
    "plt.ylabel('Voxels')\n",
    "plt.tick_params(which='both', left='off', labelleft='off', bottom='off', labelbottom='off')\n",
    "plt.xlabel('Condition A')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(pattern_B)\n",
    "plt.tick_params(which='both', left='off', labelleft='off', bottom='off', labelbottom='off')\n",
    "plt.xlabel('Condition B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3.3 Generate event time course*\n",
    "\n",
    "generate_stimfunction can be used to specify the time points at which task stimulus events occur.  The timing of events can be specified by describing the onset and duration of each event. Alternatively, it is possible to provide a path to a 3 column timing file, used by fMRI software packages like FSL, which specifies event onset, duration and weight. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up stimulus event time course parameters\n",
    "event_duration = 2  # How long is each event\n",
    "isi = 7  # What is the time between each event\n",
    "burn_in = 1  # How long before the first event\n",
    "\n",
    "total_time = int(dim[3] * tr) + burn_in  # How long is the total event time course\n",
    "events = int((total_time - ((event_duration + isi) * 2))  / ((event_duration + isi) * 2)) * 2  # How many events are there?\n",
    "onsets_all = np.linspace(burn_in, events * (event_duration + isi), events)  # Space the events out\n",
    "np.random.shuffle(onsets_all)  # Shuffle their order\n",
    "onsets_A = onsets_all[:int(events / 2)]  # Assign the first half of shuffled events to condition A\n",
    "onsets_B = onsets_all[int(events / 2):]  # Assign the second half of shuffled events to condition B\n",
    "temporal_res = 10.0 # How many timepoints per second of the stim function are to be generated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a time course of events \n",
    "stimfunc_A = fmrisim.generate_stimfunction(onsets=onsets_A,\n",
    "                                           event_durations=[event_duration],\n",
    "                                           total_time=total_time,\n",
    "                                           temporal_resolution=temporal_res,\n",
    "                                           )\n",
    "\n",
    "stimfunc_B = fmrisim.generate_stimfunction(onsets=onsets_B,\n",
    "                                           event_durations=[event_duration],\n",
    "                                           total_time=total_time,\n",
    "                                           temporal_resolution=temporal_res,\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3.4 Export stimulus time course for analysis*\n",
    "\n",
    "If a time course of events is generated, as is the case here, it may be useful to store this in a certain format for future analyses. The export_3_column function can be used to export the time course to be a three column (event onset, duration and weight) timing file that might readable to FSL. Alternatively, the export_epoch_file function can be used to export numpy files that are necessary inputs for MVPA and FCMA in BrainIAK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fmrisim.export_epoch_file(stimfunction=[np.hstack((stimfunc_A, stimfunc_B))],\n",
    "                          filename=home + '/epoch_file.npy',\n",
    "                          tr_duration=tr,\n",
    "                          temporal_resolution=temporal_res,\n",
    "                          )\n",
    "\n",
    "fmrisim.export_3_column(stimfunction=stimfunc_A,\n",
    "                        filename=home + '/Condition_A.txt',\n",
    "                        temporal_resolution=temporal_res,\n",
    "                        )\n",
    "\n",
    "fmrisim.export_3_column(stimfunction=stimfunc_B,\n",
    "                        filename=home + '/Condition_B.txt',\n",
    "                        temporal_resolution=temporal_res,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3.5 Estimate the voxel weight for each event*\n",
    "\n",
    "According to the logic of this example, each signal voxel will respond a different amount for condition A and B, but this amount will also differ across voxels. To simulate this we multiply a voxel’s response to each condition by the time course of events and then combine these conditions time courses to make a single time course. This time course describes each voxel’s response to stimuli over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Multiply each pattern by each voxel time course\n",
    "weights_A = np.matlib.repmat(stimfunc_A, 1, voxels).transpose() * pattern_A\n",
    "weights_B = np.matlib.repmat(stimfunc_B, 1, voxels).transpose() * pattern_B\n",
    "\n",
    "# Sum these time courses together\n",
    "stimfunc_weighted = weights_A + weights_B\n",
    "stimfunc_weighted = stimfunc_weighted.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3.6 Convolve each voxel’s time course with the Hemodynamic Response Function*\n",
    "\n",
    "With the time course of stimulus events it is necessary to estimate the brain’s response to those events, which can be estimated by convolving it with using a Hemodynamic Response Function (HRF). By default, convolve_hrf assumes a double gamma HRF appropriately models a brain’s response to events, as modeled by fMRI (Friston, et al., 1998). To do this, each voxel’s time course is convolved to make a function of the signal activity. Hence this produces an estimate of the voxel’s activity, after considering the temporal blurring of the HRF. This can take a single vector of events or multiple time courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "signal_func = fmrisim.convolve_hrf(stimfunction=stimfunc_weighted,\n",
    "                                   tr_duration=tr,\n",
    "                                   temporal_resolution=temporal_res,\n",
    "                                   scale_function=1,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data to be plotted\n",
    "response = signal_func[0:100,0] * 2\n",
    "downsample_A = stimfunc_A[0:int(100*temporal_res * tr):int(temporal_res * tr), 0]\n",
    "downsample_B = stimfunc_B[0:int(100*temporal_res * tr):int(temporal_res * tr), 0]\n",
    "\n",
    "# Display signal\n",
    "plt.figure()\n",
    "plt.title('Example event time course and voxel response')\n",
    "Event_A = plt.plot(downsample_A, 'r', label='Event_A')\n",
    "Event_B = plt.plot(downsample_B, 'g', label='Event_B')\n",
    "Response = plt.plot(response, 'b', label='Response')\n",
    "plt.legend(loc=1)\n",
    "plt.yticks([],'')\n",
    "plt.xlabel('nth TR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3.7 Establish signal magnitude*\n",
    "\n",
    "When specifying the signal we must determine the amount of activity change each voxel undergoes. fmrisim contains a tool to allow you to choose between a variety of different metrics that you could use to scale the signal. For instance, we can calculate percent signal change (referred to as PSC) by taking the average activity of voxels in an ROI of the noise volume and multiplying it by a proportion to signal the percentage change that this signal maximally evokes. This metric doesn't take account of the variance in the noise but other metrics available do. One metric that does take account of variance, and is used below, is the signal amplitude divided by the temporal variability. The choices that are available for computing the signal scale are based on Welvaert and Rosseel (2013)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify the parameters for signal\n",
    "signal_method = 'CNR_Amp/Noise-SD'\n",
    "signal_magnitude = [0.5]\n",
    "\n",
    "# Where in the brain are there stimulus evoked voxels\n",
    "signal_idxs = np.where(signal_volume == 1)\n",
    "\n",
    "# Pull out the voxels corresponding to the noise volume\n",
    "noise_func = noise[signal_idxs[0], signal_idxs[1], signal_idxs[2], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the signal appropriate scaled\n",
    "signal_func_scaled = fmrisim.compute_signal_change(signal_func,\n",
    "                                                  noise_func,\n",
    "                                                  noise_dict,\n",
    "                                                  magnitude=signal_magnitude,\n",
    "                                                  method=signal_method,\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3.8 Multiply the convolved response with the signal voxels*\n",
    "\n",
    "If you have a time course of simulated response for one or more voxels and a three dimensional volume representing voxels that ought to respond to these events then apply_signal will combine these appropriately. This function multiplies each signal voxel in the brain by the convolved event time course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "signal = fmrisim.apply_signal(signal_func_scaled,\n",
    "                              signal_volume,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3.9 Combine signal and noise*\n",
    "\n",
    "Since the brain signal is expected to be small and sparse relative to the noise, it is assumed sufficient to simply add the volume containing signal with the volume modeling noise to make the simulated brain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brain = signal + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Analyse data**\n",
    "\n",
    "Several tools are available for multivariate analysis in BrainIAK. These greatly speed up computation and are critical in some cases, such as a whole brain searchlight. However, for this example data we will only look at data in the ROI that we know contains signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*4.1 Pull out data for each trial*\n",
    "\n",
    "Identify which voxels are in the signal ROI by using the coordinates provided earlier. To identify the relevant timepoints, assume that the peak of the neural response occurs 4 - 6s after each event onset. Take the TR corresponding to this peak response as the TR for that trial. In longer event/block designs you might instead average over each event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hrf_lag = 4  # Assumed time from stimulus onset to HRF peak\n",
    "\n",
    "# Get the lower and upper bounds of the ROI\n",
    "lb = (coordinates - ((feature_size - 1) / 2)).astype('int')[0]\n",
    "ub = (coordinates + ((feature_size - 1) / 2) + 1).astype('int')[0]\n",
    "\n",
    "# Pull out voxels in the ROI for the specified timepoints\n",
    "trials_A = brain[lb[0]:ub[0], lb[1]:ub[1], lb[2]:ub[2], ((onsets_A + hrf_lag) / tr).astype('int')]\n",
    "trials_B = brain[lb[0]:ub[0], lb[1]:ub[1], lb[2]:ub[2], ((onsets_B + hrf_lag) / tr).astype('int')]\n",
    "\n",
    "# Reshape data for easy handling\n",
    "trials_A = trials_A.reshape((voxels, trials_A.shape[3]))\n",
    "trials_B = trials_B.reshape((voxels, trials_B.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the pattern of activity for our signal voxels at each timepoint\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(trials_A)\n",
    "plt.ylabel('Voxels')\n",
    "plt.xlabel('Trials')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(trials_B)\n",
    "plt.xlabel('Trials')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*4.2 Represent the data*\n",
    "\n",
    "Treat each voxel as a dimension and each trial as a point in this voxel space. It is then possible to display the different conditions and determine whether these are separable in this lower dimensionality (note that the conditions may be separable in higher dimensionality but unsupervised techniques like Multidimensional Scaling used below, might not show such a difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance matrix between trial types\n",
    "distance_matrix = sp_distance.squareform(sp_distance.pdist(np.vstack([trials_A.transpose(), trials_B.transpose()])))\n",
    "\n",
    "mds = manifold.MDS(n_components=2, dissimilarity='precomputed')  # Fit the mds object\n",
    "coords = mds.fit(distance_matrix).embedding_  # Find the mds coordinates\n",
    "\n",
    "# Plot the data\n",
    "plt.figure()\n",
    "plt.scatter(coords[:, 0], coords[:, 1], c=['red'] * trials_A.shape[1] + ['green'] * trials_B.shape[1])\n",
    "plt.axis('off')\n",
    "plt.title('Low Dimensional Representation of conditions A and B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*4.2 Test for univariate effect*\n",
    "\n",
    "Do a t test to compare the means of the voxels between these two conditions to determine if there is a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_difference = (np.mean(trials_A,0) - np.mean(trials_B,0))\n",
    "ttest = stats.ttest_1samp(mean_difference, 0)\n",
    "\n",
    "print('Mean difference between condition A and B: %0.2f\\np value: %0.3f' % (mean_difference.mean(), ttest.pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*4.3 Test for a multivariate effect*\n",
    "\n",
    "Use SVM from scikit-learn to estimate the classification accuracy between the conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the inputs to the SVM\n",
    "input_mat = np.vstack([trials_A.transpose(), trials_B.transpose()])\n",
    "input_labels = trials_A.shape[1] * [1] + trials_B.shape[1] * [0]\n",
    "\n",
    "# Set up the classifier\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    input_mat, input_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "clf = sklearn.svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "\n",
    "score = clf.score(X_test, y_test)\n",
    "print('Classification accuracy between condition A and B: %0.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### **References**\n",
    "Biswal, B., et al. (1996) Reduction of physiological fluctuations in fMRI using digital filters. Magnetic Resonance in Medicine 35, 107-113\n",
    "\n",
    "Friedman, L. and Glover, G.H. (2006) Report on a multicenter fMRI quality assurance protocol. Journal of Magnetic Resonance Imaging 23, 827-839\n",
    "\n",
    "Friston, K.J., et al. (1998) Event-related fMRI: characterizing differential responses. Neuroimage 7, 30-40\n",
    "\n",
    "Gudbjartsson, H. and Patz, S. (1995) The Rician distribution of noisy MRI data. Magnetic resonance in medicine 34, 910-914\n",
    "\n",
    "Welvaert, M., et al. (2011) neuRosim: An R package for generating fMRI data. Journal of Statistical Software 44, 1-18\n",
    "\n",
    "Welvaert, M., & Rosseel, Y. (2013). On the definition of signal-to-noise ratio and contrast-to-noise ratio for fMRI data. PloS one, 8(11), e77089.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
