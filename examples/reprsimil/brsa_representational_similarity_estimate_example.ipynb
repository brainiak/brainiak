{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This demo shows how to use the Bayesian Representational Similarity Analysis method in brainiak with a simulated dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load some package which we will use in this demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy.stats\n",
    "import scipy.spatial.distance as spdist\n",
    "import numpy as np\n",
    "from brainiak.reprsimil.brsa import BRSA\n",
    "import brainiak.utils.utils as utils\n",
    "import os.path\n",
    "import numdifftools as nd\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You might want to keep a log of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, filename='brsa_example.log',\n",
    "                    format='%(relativeCreated)6d %(threadName)s %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) We want to simulate some data in which each voxel respond to different task conditions differently, but following a common covariance structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an example design matrix.\n",
    "The user should prepare their design matrix with their favorate software, such as using 3ddeconvolve of AFNI, or using SPM or FSL.\n",
    "The design matrix reflects your belief of how fMRI signal should respond to a task (if a voxel does respond).\n",
    "The common assumption is that a neural event that you are interested in will elicit a slow hemodynamic response in some voxels. The response peaks around 4-6 seconds after the event onset and dies down more than 12 seconds after the event. Therefore, typically you convolve a time series A, composed of delta (stem) functions reflecting the time of each neural event belonging to the same category (e.g. all trials in which a participant sees a face), with a hemodynamic response function B, to form the hypothetic response of any voxel to such type of neural event.\n",
    "For each type of event, such a convoluted time course can be generated. These time courses, put together, are called design matrix, reflecting what we believe a temporal signal would look like, if it exists in any voxel.\n",
    "Our goal is to figure out how the (spatial) response pattern of a population of voxels (in an Region of Interest, ROI) are similar or disimilar to different types of tasks (e.g., watching face vs. house, watching different categories of animals, different conditions of a cognitive task). So we need the design matrix in order to estimate the similarity matrix we are interested.\n",
    "\n",
    "We can use the utility called ReadDesign to read a design matrix generated from AFNI. For design matrix saved as Matlab data file by SPM or or other toolbox, you can use scipy.io.loadmat('YOURFILENAME') and extract the design matrix from the dictionary returned. Basically, the Bayesian RSA in this toolkit just needs a numpy array which is in size of {time points} * {condition}\n",
    "\n",
    "The design matrix we load in this demo has 16 different conditions. The baseline level in different voxels might be different even if you z-score the data. Therefore, we need to take into account possible different baseline. Currently, our method put an additional condition composed of all 1's (DC component) into the design matrix for this goal. Very soon, we will have a version which treats baseline level and other not interested signals shared across voxels separately from the signals we are interested in.\n",
    "### We concatenate the design matrix by 2 times, mimicking 2 runs of identical timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "design = utils.ReadDesign(fname=\"example_design.1D\")\n",
    "\n",
    "\n",
    "design.design_used = np.tile(design.design_used[:,0:17],[2,1])\n",
    "design.n_TR = design.n_TR * 2\n",
    "\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(12, 3), dpi=150, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(design.design_used)\n",
    "plt.ylim([-0.2,1.2])\n",
    "plt.title('hypothetic fMRI response time courses of all conditions in addition to a DC component\\n'\n",
    "         '(design matrix)')\n",
    "plt.xlabel('time')\n",
    "plt.show()\n",
    "\n",
    "n_C = np.size(design.design_used,axis=1) \n",
    "# The total number of conditions.\n",
    "ROI_edge = 25\n",
    "# We simulate \"ROI\" of a square shape\n",
    "n_V = ROI_edge**2\n",
    "# The total number of simulated voxels\n",
    "n_T = design.n_TR\n",
    "# The total number of time points, after concatenating all fMRI runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simulate data: noise + signal\n",
    "### First, we start with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noise_bot = 0.5\n",
    "noise_top = 1.5\n",
    "noise_level = np.random.rand(n_V)*(noise_top-noise_bot)+noise_bot\n",
    "# The standard deviation of the noise is in the range of [noise_bot, noise_top]\n",
    "# In fact, we simulate autocorrelated noise with AR(1) model. So the noise_level reflects\n",
    "# the independent additive noise at each time point (the \"fresh\" noise)\n",
    "\n",
    "# AR(1) coefficient\n",
    "rho1_top = 0.8\n",
    "rho1_bot = -0.2\n",
    "rho1 = np.random.rand(n_V)*(rho1_top-rho1_bot)+rho1_bot\n",
    "\n",
    "\n",
    "# generating noise\n",
    "noise = np.zeros([n_T,n_V])\n",
    "noise[0,:] = np.random.randn(n_V) * noise_level / np.sqrt(1-rho1**2)\n",
    "for i_t in range(1,n_T):\n",
    "    noise[i_t,:] = noise[i_t-1,:] * rho1 +  np.random.randn(n_V) * noise_level\n",
    "# Here, we assume noise is independent between voxels\n",
    "fig = plt.figure(num=None, figsize=(12, 2), dpi=150, facecolor='w', edgecolor='k')\n",
    "plt.plot(noise[:,0])\n",
    "plt.title('noise in an example voxel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, we simulate signals, assuming the magnitude of response to each condition follows a common covariance matrix\n",
    "#### Our model allows to impose a Gaussian Process prior on the log(SNR) of each voxels. \n",
    "What this means is that SNR turn to be smooth and local, but betas (response amplitudes of each voxel to each condition) are not necessarily correlated in space. Intuitively, this is based on the assumption that voxels coding for related aspects of a task turn to be clustered (instead of isolated)\n",
    "\n",
    "Our Gaussian Process are defined on both the coordinate of a voxel and its mean intensity.\n",
    "This means that voxels close together AND have similar intensity should have similar SNR level. Therefore, voxels of white matter but adjacent to gray matters do not necessarily have high SNR level.\n",
    "\n",
    "If you have an ROI saved as a binary Nifti file, say, with name 'ROI.nii'\n",
    "Then you can use nibabel package to load the ROI and the following example code to retrive the coordinates of voxels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: the following code won't work if you just installed Brainiak. It serves as an example for you to retrieve coordinates of voxels in an ROI. You can use the ROI_coords for the argument coords in BRSA.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import nibabel\n",
    "# ROI = nibabel.load('ROI.nii')\n",
    "# I,J,K = ROI.shape \n",
    "# all_coords = np.zeros((I, J, K, 3)) \n",
    "# all_coords[...,0] = np.arange(I)[:,np.newaxis,np.newaxis] \n",
    "# all_coords[...,1] = np.arange(J)[np.newaxis,:,np.newaxis] \n",
    "# all_coords[...,2] = np.arange(K)[np.newaxis,np.newaxis,:] \n",
    "# ROI_coords = nibabel.affines.apply_affine(ROI.affine, all_coords[ROI.get_data().astype(bool)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's keep in mind of the pattern of the ideal covariance / correlation below and see how well BRSA can recover their patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ideal covariance matrix\n",
    "ideal_cov = np.zeros([n_C,n_C])\n",
    "ideal_cov = np.eye(n_C)*0.6\n",
    "ideal_cov[0,0] = 0.1\n",
    "ideal_cov[9:13,9:13] = 0.8\n",
    "for cond in range(9,13):\n",
    "    ideal_cov[cond,cond] = 1\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(4, 4), dpi=100)\n",
    "plt.pcolor(ideal_cov)\n",
    "plt.colorbar()\n",
    "plt.xlim([0,17])\n",
    "plt.ylim([0,17])\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "plt.title('ideal covariance matrix')\n",
    "plt.show()\n",
    "\n",
    "std_diag = np.diag(ideal_cov)**0.5\n",
    "ideal_corr = ideal_cov / std_diag / std_diag[:,None]\n",
    "fig = plt.figure(num=None, figsize=(4, 4), dpi=100)\n",
    "plt.pcolor(ideal_corr)\n",
    "plt.colorbar()\n",
    "plt.xlim([0,17])\n",
    "plt.ylim([0,17])\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "plt.title('ideal correlation matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the following, pseudo-SNR is generated from a Gaussian process defined on a \"linear\" ROI, just for simplicity of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "L_full = np.linalg.cholesky(ideal_cov)        \n",
    "\n",
    "# generating signal\n",
    "snr_level = 0.5\n",
    "# Notice that accurately speaking this is not snr. the magnitude of signal depends\n",
    "# not only on beta but also on x. (noise_level*snr_level)**2 is the factor multiplied\n",
    "# with ideal_cov to form the covariance matrix from which the response amplitudes (beta)\n",
    "# of a voxel are drawn from.\n",
    "\n",
    "tau = 0.8\n",
    "# magnitude of Gaussian Process from which the log(SNR) is drawn\n",
    "smooth_width = 3.0\n",
    "# spatial length scale of the Gaussian Process, unit: voxel\n",
    "inten_kernel = 4.0\n",
    "# intensity length scale of the Gaussian Process\n",
    "# Slightly counter-intuitively, if this parameter is very large,\n",
    "# say, much larger than the range of intensities of the voxels,\n",
    "# then the smoothness has much small dependency on the intensity.\n",
    "\n",
    "\n",
    "coords = np.mgrid[0:ROI_edge, 0:ROI_edge, 0:1]\n",
    "coords_flat = np.reshape(coords,[3, n_V]).T\n",
    "dist2 = spdist.squareform(spdist.pdist(coords_flat, 'sqeuclidean'))\n",
    "\n",
    "inten = np.random.rand(n_V) * 20.0\n",
    "# For simplicity, we just assume that the intensity of all voxels are uniform distributed between 0 and 20\n",
    "# parameters of Gaussian process to generate pseuso SNR\n",
    "# For curious user, you can also try the following commond\n",
    "# to see what an example snr map might look like if the intensity\n",
    "# grows linearly in one spatial direction\n",
    "\n",
    "# inten = coords_flat[:,0] * 2\n",
    "\n",
    "\n",
    "inten_tile = np.tile(inten,[n_V,1])\n",
    "inten_diff2 = (inten_tile-inten_tile.T)**2\n",
    "\n",
    "K = np.exp(-dist2/smooth_width**2/2.0 -inten_diff2/inten_kernel**2/2.0) * tau**2 \\\n",
    "    + np.eye(n_V)*tau**2*0.001\n",
    "# A tiny amount is added to the diagonal of the GP covariance matrix to make sure it can be inverted\n",
    "L = np.linalg.cholesky(K)\n",
    "snr = np.exp(np.dot(L,np.random.randn(n_V))) * snr_level\n",
    "sqrt_v = noise_level*snr\n",
    "betas_simulated = np.dot(L_full,np.random.randn(n_C,n_V)) * sqrt_v\n",
    "signal = np.dot(design.design_used,betas_simulated)\n",
    "\n",
    "\n",
    "Y = signal + noise\n",
    "# The data to be fed to the program.\n",
    "\n",
    "\n",
    "idx = np.argmin(np.abs(snr-np.median(snr)))\n",
    "# choose a voxel of medium level SNR.\n",
    "fig = plt.figure(num=None, figsize=(12, 4), dpi=150, facecolor='w', edgecolor='k')\n",
    "noise_plot, = plt.plot(noise[:,idx],'g')\n",
    "signal_plot, = plt.plot(signal[:,idx],'r')\n",
    "plt.legend([noise_plot, signal_plot], ['noise', 'signal'])\n",
    "plt.title('simulated data in an example voxel with pseudo-SNR of {}'.format(snr[idx]))\n",
    "plt.xlabel('time')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(12, 4), dpi=150, facecolor='w', edgecolor='k')\n",
    "data_plot, = plt.plot(Y[:,idx],'b')\n",
    "plt.legend([data_plot], ['observed data'])\n",
    "plt.xlabel('time')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(4, 4), dpi=100)\n",
    "plt.pcolor(np.reshape(snr, [ROI_edge, ROI_edge]))\n",
    "plt.colorbar()\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "plt.title('pseudo-SNR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The reason that the pseudo-SNR in the example voxel is not too small, while the signal looks much smaller is because we happen to have low amplitudes in our design matrix. The True SNR depends on both the amplitudes in design matrix and the pseudo-SNR. Therefore, be aware that pseudo-SNR does not directly reflects how much signal the data have, but rather a map indicating the relative strength of signal in differerent voxels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When you have multiple runs, the noise won't be correlated between runs. Therefore, you should tell BRSA when is the onset of each scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scan_onsets = np.linspace(0,design.n_TR,num=3)[:-1]\n",
    "print('scan onsets: {}'.format(scan_onsets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Fit Bayesian RSA to our simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brsa = BRSA(GP_space=True,GP_inten=True,tau_range=10)\n",
    "# Initiate an instance, telling it that we want to impose Gaussian Process prior over both space and intensity.\n",
    "\n",
    "brsa.fit(X=Y, design=design.design_used, scan_onsets=scan_onsets,\n",
    "         coords=coords_flat, inten=inten)\n",
    "# The data to fit should be given to the argument X. Design matrix goes to design. And so on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can have a look at the estimated similarity in matrix brsa.C_ \n",
    "### We can also compare the ideal covariance above with the one recovered, brsa.U_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(num=None, figsize=(4, 4), dpi=100)\n",
    "plt.pcolor(brsa.C_[1:, 1:], vmin=-0.1, vmax=1)\n",
    "plt.xlim([0, 16])\n",
    "plt.ylim([0, 16])\n",
    "plt.colorbar()\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "plt.title('Estimated correlation structure\\n shared between voxels\\n'\n",
    "         'This constitutes the output of BRSA\\n')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(4, 4), dpi=100)\n",
    "plt.pcolor(brsa.U_)\n",
    "plt.xlim([0, 17])\n",
    "plt.ylim([0, 17])\n",
    "plt.colorbar()\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "plt.title('Estimated covariance structure\\n shared between voxels\\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In contrast, we can have a look of the similarity matrix based on Pearson correlation between point estimates of betas of different conditions.\n",
    "## This is what vanila RSA might give"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betas_point = np.linalg.lstsq(design.design_used, Y)[0]\n",
    "point_corr = np.corrcoef(betas_point)\n",
    "point_cov = np.cov(betas_point) \n",
    "fig = plt.figure(num=None, figsize=(4, 4), dpi=100)\n",
    "plt.pcolor(point_corr[1:, 1:], vmin=-0.1, vmax=1)\n",
    "plt.xlim([0, 16])\n",
    "plt.ylim([0, 16])\n",
    "plt.colorbar()\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "plt.title('Correlation structure estimated\\n'\n",
    "         'based on point estimates of betas\\n')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(4, 4), dpi=100)\n",
    "plt.pcolor(point_cov[1:, 1:])\n",
    "plt.xlim([0, 16])\n",
    "plt.ylim([0, 16])\n",
    "plt.colorbar()\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "plt.title('Covariance structure of\\n'\n",
    "         'point estimates of betas\\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can make a comparison between the estimated SNR map and the true SNR map (normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(num=None, figsize=(5, 5), dpi=100)\n",
    "plt.pcolor(np.reshape(brsa.nSNR_, [ROI_edge, ROI_edge]), vmin=0, vmax=5)\n",
    "plt.colorbar()\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "ax.set_title('estimated pseudo-SNR')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(5, 5), dpi=100)\n",
    "plt.pcolor(np.reshape(snr / np.exp(np.mean(np.log(snr))), [ROI_edge, ROI_edge]), vmin=0, vmax=5)\n",
    "plt.colorbar()\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "ax.set_title('true normalized pseudo-SNR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RMS_BRSA = np.mean((brsa.C_[1:,1:] - ideal_corr[1:,1:])**2)**0.5\n",
    "RMS_RSA = np.mean((point_corr[1:,1:] - ideal_corr[1:,1:])**2)**0.5\n",
    "print('RMS error of Bayesian RSA: {}'.format(RMS_BRSA))\n",
    "print('RMS error of standard RSA: {}'.format(RMS_RSA))\n",
    "print('Recovered spatial smoothness length scale: {}, vs. true value: {}'.format(brsa.lGPspace_, smooth_width))\n",
    "print('Recovered intensity smoothness length scale: {}, vs. true value: {}'.format(brsa.lGPinten_, inten_kernel))\n",
    "print('Recovered standard deviation of GP prior: {}, vs. true value: {}'.format(brsa.bGP_, tau))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empirically, the smoothness turns to be over-estimated when signal is weak."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
