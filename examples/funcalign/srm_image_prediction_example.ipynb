{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some libraries that we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy.io\n",
    "from scipy.stats import stats\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import NuSVC\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run SRM with the movie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import brainiak.funcalign.srm\n",
    "help(brainiak.funcalign.srm.SRM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the input data that contains the movie stimuli for unsupervised training with SRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_file = scipy.io.loadmat('data/movie_data.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data to a list of arrays matching SRM input.\n",
    "Each element is a matrix of voxels by TRs.\n",
    "Also, concatenate data from both hemispheres in the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_data_left = movie_file['movie_data_lh']\n",
    "movie_data_right = movie_file['movie_data_rh']\n",
    "subjects = movie_data_left.shape[2]\n",
    "movie_data = []\n",
    "for s in range(subjects):\n",
    "    movie_data.append(np.concatenate([movie_data_left[:, :, s], movie_data_right[:, :, s]], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z-score the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for subject in range(subjects):\n",
    "    movie_data[subject] = stats.zscore(movie_data[subject],axis=1,ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run SRM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srm = brainiak.funcalign.srm.SRM(n_iter=10, features=50)\n",
    "srm.fit(movie_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the input data that contains the image stimuli and its labels for training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_file = scipy.io.loadmat('data/image_data.mat')\n",
    "image_data_left = image_file['image_data_lh']\n",
    "image_data_right = image_file['image_data_rh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data to a list of arrays matching SRM input. Each element is a matrix of voxels by TRs. Also, concatenate data from both hemispheres in the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_data = []\n",
    "for s in range(subjects):\n",
    "    image_data.append(np.concatenate([image_data_left[:, :, s], image_data_right[:, :, s]], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z-score the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for subject in range(subjects):\n",
    "    image_data[subject] = stats.zscore(image_data[subject],axis=1,ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z-score the Shared Response data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_data_shared = srm.transform(image_data)\n",
    "for subject in range(subjects):\n",
    "    image_data_shared[subject] = stats.zscore(image_data_shared[subject], axis=1, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the labels of the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = scipy.io.loadmat('data/label.mat')\n",
    "labels = np.squeeze(labels['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a leave-one-out cross validation with the subjects. We use a $\\nu$-SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = np.tile(labels, subjects-1)\n",
    "test_labels = labels\n",
    "accuracy = np.zeros((subjects))\n",
    "cm = [None] * subjects\n",
    "for subject in range(subjects):\n",
    "    # Concatenate the subjects' data for training into one matrix\n",
    "    train_subjects = list(range(subjects))\n",
    "    train_subjects.remove(subject)\n",
    "    TRs = image_data_shared[0].shape[1]\n",
    "    train_data = np.zeros((image_data_shared[0].shape[0], len(train_labels)))\n",
    "    for train_subject in range(len(train_subjects)):\n",
    "        start_index = train_subject*TRs\n",
    "        end_index = start_index+TRs\n",
    "        train_data[:, start_index:end_index] = image_data_shared[train_subjects[train_subject]]\n",
    "\n",
    "    # Train a Nu-SVM classifier using scikit learn\n",
    "    classifier = NuSVC(nu=0.5, kernel='linear')\n",
    "    classifier = classifier.fit(train_data.T, train_labels)\n",
    "\n",
    "    # Predict on the test data\n",
    "    predicted_labels = classifier.predict(image_data_shared[subject].T)\n",
    "    accuracy[subject] = sum(predicted_labels == test_labels)/float(len(predicted_labels))\n",
    "\n",
    "    # Create a confusion matrix to see the accuracy of each class\n",
    "    cm[subject] = confusion_matrix(test_labels, predicted_labels)\n",
    "\n",
    "    # Normalize the confusion matrix\n",
    "    cm[subject] = cm[subject].astype('float') / cm[subject].sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that presents the output of the experiment in a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title=\"Confusion Matrix\"):\n",
    "    \"\"\"Plots a confusion matrix for each subject\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import math\n",
    "    plt.figure()\n",
    "    subjects = len(cm)\n",
    "    root_subjects = math.sqrt(subjects)\n",
    "    cols = math.ceil(root_subjects)\n",
    "    rows = math.ceil(subjects/cols)\n",
    "    classes = cm[0].shape[0]\n",
    "    for subject in range(subjects):\n",
    "        plt.subplot(rows, cols, subject+1)\n",
    "        plt.imshow(cm[subject], interpolation='nearest', cmap=plt.cm.bone)\n",
    "        plt.xticks(np.arange(classes), range(1,classes+1))\n",
    "        plt.yticks(np.arange(classes), range(1,classes+1))\n",
    "        cbar = plt.colorbar(ticks=[0.0,1.0], shrink=0.6)\n",
    "        cbar.set_clim(0.0, 1.0)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True label\")\n",
    "        plt.title(\"{0:d}\".format(subject + 1))\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Plot the confusion matrices and print the accuracy results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, title=\"Confusion matrices for different test subjects\")\n",
    "print(\"The average accuracy among all subjects is {0:f} +/- {1:f}\".format(np.mean(accuracy), np.std(accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we repeat the experiment with the Deterministic SRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srm = brainiak.funcalign.srm.DetSRM(n_iter=10, features=50)\n",
    "srm.fit(movie_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the image stimuli data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_data_shared = srm.transform(image_data)\n",
    "for subject in range(subjects):\n",
    "    image_data_shared[subject] = stats.zscore(image_data_shared[subject], axis=1, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a leave-one-out cross validation with the subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = np.zeros((subjects,))\n",
    "cm = [None] * subjects\n",
    "for subject in range(subjects):\n",
    "    # Concatenate the subjects' data for training into one matrix\n",
    "    train_subjects = list(range(subjects))\n",
    "    train_subjects.remove(subject)\n",
    "    TRs = image_data_shared[0].shape[1]\n",
    "    train_data = np.zeros((image_data_shared[0].shape[0], len(train_labels)))\n",
    "    for train_subject in range(len(train_subjects)):\n",
    "        start_index = train_subject*TRs\n",
    "        end_index = start_index+TRs\n",
    "        train_data[:, start_index:end_index] = image_data_shared[train_subjects[train_subject]]\n",
    "\n",
    "    # Train a Nu-SVM classifier using scikit learn\n",
    "    classifier = NuSVC(nu=0.5, kernel='linear')\n",
    "    classifier = classifier.fit(train_data.T, train_labels)\n",
    "\n",
    "    # Predict on the test data\n",
    "    predicted_labels = classifier.predict(image_data_shared[subject].T)\n",
    "    accuracy[subject] = sum(predicted_labels == test_labels)/float(len(predicted_labels))\n",
    "\n",
    "    # Create a confusion matrix to see the accuracy of each class\n",
    "    cm[subject] = confusion_matrix(test_labels, predicted_labels)\n",
    "\n",
    "    # Normalize the confusion matrix\n",
    "    cm[subject] = cm[subject].astype('float') / cm[subject].sum(axis=1)[:, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, title=\"Confusion matrices for different test subjects with Deterministic SRM\")\n",
    "print(\"Det. SRM: The average accuracy among all subjects is {0:f} +/- {1:f}\".format(np.mean(accuracy), np.std(accuracy)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
